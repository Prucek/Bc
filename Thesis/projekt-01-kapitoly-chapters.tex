% Autor: Peter Rúček

\chapter{Úvod}

Keď sa zrodí nápad na knihu, je spočiatku jedno, o aký príbeh ide. Skvelý nápad je skvelý nápad. Ale definovanie typu príbehu, pochopenie základných tém a poznanie, kam príbeh komerčne patrí, jasne pomáha určiť štruktúru aj smer.

Pokiaľ ide o žánre a typy zápletiek, počet rôznych druhov sa pohybuje od 1 po čokoľvek. Žánre sa formujú podľa konvencií, ktoré sa časom menia, keďže kultúry vymýšľajú nové žánre a prestávajú používať staré. Diela často zapadajú do viacerých žánrov prostredníctvom vypožičiavania a rekombinácie týchto konvencií. No napriek tomu sa žánre stali najpopulárnejším spôsobom ako klasifikovať umenie.

Naproti tomu typy zápletiek sú viac-menej nemenné, a predsa skoro vôbec nepoužívané. Pre dejové línie typu \textit{morálne dilema} alebo \textit{zneužitie sily} bolo určite napísaných, a určite ešte aj bude, veľa kníh. Definovanie však týchto základných kľúčových dejových línií je problematické. Na toto téma bolo napísaných viacero kníh a článkov, no myšlienky autorov sú veľmi odlišné a nevedia sa zhodnúť ani v tom koľko by ich malo asi byť. Niektorý tvrdia, že ich je 20, iný ich rátajú v tisícoch. 

Táto práca sa zameriava na hľadanie týchto kľúčových dejových línií v zhrnutiach dejov a užívateľských recenziách, ktoré sa získavajú zo sociálnych sietí. Systém je navrhnutý tak, že dokáže pracovať s akýmkoľvek dejom a na základe strojového učenia systém predpovedá o aký typ deja by sa podľa jeho názoru mohlo jednať.

Ciele tejto práce by sa dali využiť v sociálnych sieťach týkajúcich sa nielen kníh, kde by diela mohli byť klasifikované podľa týchto kľúčových dejových línií. Slúžili by pri vyhľadávaní, keď si užívateľ nevie spomenúť na názov knihy alebo by sa mohli takto hľadať podobnosti v dielach a navrhovať tak obdobné pri prezeraní konkrétnej knihy.

Práca je členená do siedmych kapitol. V kapitole \ref{teoria} je uvedený teoretický pohľad, potrebný pre pochopenie problematiky. Zaoberá sa popisom deja, prehľadávaním webu, klasifikačnými metódami a následne uvedením doterajších a aj súčasných prístupov strojového učenia v spracovaní prirodzeného jazyka. Dôležitou časťou je popis dát, tomu je venovaná kapitola \ref{data}. Návrhom výsledného systému analýz sa venuje kapitola \ref{navrh}. Nasleduje kapitola \ref{implementacia}, v ktorej je popísaná implementácia tohoto systému. Kapitola \ref{experimenty} popisuje jednotlivé experimenty nad dátami. Záverečná \ref{zaver}. kapitola zhodnocuje ciele systému a dosiahnuté výsledky.

\chapter{Rozbor riešenej problematiky }
\label{teoria}

Táto kapitola obsahuje základné teoretické znalosti, z ktorých sa vychádza pri návrhu systému a následne pri jeho realizácii. Táto práca sa zaoberá vytvorením systému pre analýzu dejových línií zo zhrnutí dejov. Jednotlivé podkapitoly sa viažu k samotnému návrhu systému.
Najskôr je popísané, čo je to dej, aké existujú kľúčové dejové línie a ako ich rôzny autori definujú. Následne je popísané ako sa získavajú dáta z webu. Potom je bližšie priblížený problém klasifikácie. Ďalej sú v rýchlosti uvedené základné klasifikačné metódy, hlbšie sú potom spomenuté neuronové siete a konkrétne Transformer a BERT. Záverečné podkapitoly sú venované metrikám vyhodnocovania a matrikám podobnosti.


\section{Príbeh}
Základom pre pochopenie kľúčových dejových línií a ich analýzu je pochopenie čo je to príbeh, z čoho sa skladá a ako to súvisí s dejom. Nasledujúce podkapitoly vychádzajú \linebreak
z \cite{Rosaria:2004} a \cite{Roberts:1987}.

\subsection*{Dej}

Dej je základ pre príbeh, založený na protichodných ľudských motiváciách, s činmi vyplývajúcimi z uveriteľnej a realistickej ľudskej reakcie. To znamená, že konflikt je základná časť, ktorú je potrebné vytvoriť, aby sa vytvoril súbor udalostí pri formovaní príbehu. Konflikt určí ďalšiu akciu alebo situáciu. Bude to určujúci faktor pre vytvorenie hlavnej štruktúry príbehu.
 
Dejom príbehu je teda nastolenie konfliktu a dôsledky, variácie a vývoj, ktoré z neho pramenia. Ďalej ním myslíme myšlienku, ktorá určuje, ako bude príbeh plynúť. Teda bude spájať jednu akciu s druhou, aby bol príbeh dobre organizovaný. V dobre vykreslenom príbehu nie je nič irelevantné; všetko spolu súvisí. V príbehu je čas dôležitý nielen preto, že jedna vec sa deje za druhou, ale preto, že jedna vec sa deje kvôli druhej.

Tak ako dej plynie, možno väčšinu dejov zaradiť do tejto tradičnej dejovej štruktúry, viď obrázok \ref{climax} :
\begin{itemize}
	\item \textbf{Expozícia (Úvod):} Expozícia je rozloženie a uvedenie základných prvkov v príbehu: hlavné postavy, ich pozadie, ich charakteristiky, ciele, obmedzenia a potenciál. Predstavuje všetko, čo bude v príbehu dôležité.
    \item \textbf{Kolízia (Zápletka):} Kolízia označuje začiatok veľkého konfliktu v príbehu. Účastníkmi sú protagonisti a antagonisti, spolu s akýmikoľvek myšlienkami alebo hodnotami, ktoré predstavujú, akými sú dobro a zlo, individualizmus a kolektivizmus, láska a nenávisť, inteligencia a hlúposť, vedomosti a nevedomosť, sloboda a otroctvo, túžba a odpor a podobne.
    \item \textbf{Kríza (Vyvrcholenie, Climax):} Kríza je bod zlomu, oddeľujúci medzi tým, čo bolo predtým, a tým, čo príde potom. Naplno sa v ňom prejaví konflikt a následné napätie. Ďalším spôsobom, ako myslieť na vyvrcholenie, je definovať ho ako bod v príbehu, v ktorom sa všetka ostatná akcia stáva nevyhnutnou.
    \item \textbf{Peripetia (Dejový obrat):} Peripetiou rozumieme nečakaný dejový zvrat, nepredpokladanú zmenu situácie. Dej sa zrýchľuje a smeruje ku koncu.
    \item \textbf{Katastrofa (Rozuzlenie):} Rozuzlenie je súbor akcií, ktorými sa príbeh končí. Hlavné akcie sú dokončené a posledná akcia podčiarkuje tón konečnosti.
\end{itemize}
\begin{figure}[hbt]
	\centering
	\includegraphics[width=0.8\textwidth]{obrazky-figures/climax.png}
	\caption{Štruktúra deja. Prebrané z \cite{ClimaxImage}.}
	\label{climax}
\end{figure}



\subsection*{Postavy}
Postavy sú osoby prezentované v diele, ktoré čitateľ interpretuje ako osoby obdarené morálnymi a dispozičnými vlastnosťami, ktoré sú vyjadrené tým, čo hovoria a čo robia.
Na základe dôležitosti možno postavu rozdeliť do dvoch kategórií: hlavná postava a vedľajšia postava. V celom príbehu sa zvyčajne objavuje hlavná postava, stáva sa stredobodom príbehu. Udalosti, ktoré sa v príbehu dejú, sa ho vždy priamo či nepriamo týkajú. Na druhej strane, u vedľajších postáv sú úlohy menej dôležité ako u hlavnej postavy, pretože nie sú plne rozvinutými postavami a ich úlohy v príbehu sú len na podporu vývoja hlavnej postavy.

\subsection*{Prostredie}
Prostredie diela sa vzťahuje na prírodnú a umelú scenériu, v ktorom postavy žijú a pohybujú sa. Znamená to, že všetko, čo súvisí s prostredím, ako napr. denné svetlo, stromy, zvieratá, spoločnosť, popisované zvuky, pachy a počasie sú súčasťou prostredia. Dejiskom diela je opis predmetov a fyzického vzhľadu miesta, kde sa príbeh odohráva.
Popis prostredia pomáha pri vytváraní dôveryhodnosti; môže pomôcť vysvetliť postavy aj situáciu; môže prispieť k atmosfére alebo prevládajúcej nálade; môže byť aktívny v predpovedaní; môže byť symbolickým. Okrem symboliky hlavných postáv sa prostredie používa aj ako prostriedok na posilnenie témy, znamená to, že prostredie sa považuje za dôležitú úlohu v príbehu a analýze.

\todo{hlavná dejová línia vs. vedľajšie, vzťah k dĺžke zhrnutia deja,}


\section{Kľúčové dejové línie}
\label{kdl}
Pojem \textit{kľúčové dejové línie} nemožno exaktne definovať. V starovekom Grécku rozlišovali 
2 druhy deja: komédiu a tragédiu, no odvtedy sa delenie dejových línií posunulo ďalej. V minulosti sa o nájdenie rozdelenia deja pokúšalo veľa významných dramatikov, či spisovateľov, medzi nimi aj Shiller\footnote{Friedrich Schiller -- nemecký dramatik (1759--1805)} či Gozzi\footnote{Carlo Gozzi -- taliansky dramatik (1720--1806)}. Na posledného menovaného nadväzuje kniha \uv{The Thirty Six Dramatic Situations} \cite{Polti:1921}, ktorá je jednou z mála kníh, ktorá sa zaoberá klasifikovaním deja. Ako z názvu vyplýva, predkladá 36 dramatických situácií, ktoré sú aj na dnešnú dobu aktuálne, no kniha udáva aj konkrétne deje pod každou dramatickou situáciou, tie sú však z väčšiny zastaralé a v dnešnej dobe nepoužiteľné.

Ľudia odpradávna hľadajú idey pre vymýšľanie nových kníh, či filmov, preto možno hľadať kľúčové dejové línie najmä v knihách, ktoré sa zaoberajú inšpirovaním o témach a dejových líniách, o ktorých by mohli ich čitateľa písať. 

Jednou z takýchto kníh je \uv{Plotto} \cite{Cook:1928}, ktorá mala autorom pomôcť \textit{poskladať si} príbeh. Toto dielo prezentuje tisíce veľmi podrobných dejových línií, tzv. \textit{Masterplot}. Každá táto dejová línia pozostáva z 3 \textit{klauzúl}. Kde klauzula A reprezentuje druh protagonistu, klauzula B uvádza základnú myšlienku deja a klauzula C ukončuje dej. Keďže B klauzuly sú veľmi všeobecné, každá B klauzula pozostáva z desiatok podrobnejších dejov. Tieto podrobné deje, môžu na seba rôzne navzájom nadväzovať a vytvoriť tak celkom konkrétny podrobný dej. Celkovo počet dejov, ktorý sa týmto mechanizmom dokáže vytvoriť možno rátať v státisícoch.

Ďalšou knihou z tejto kategórie je \uv{20 Master Plots: And How to Build Them} \cite{Tobias:1993} v ktorej autor prednáša, ako opäť z názvu vyplýva, 20 oblastí ktorých sa môže týkať dej. Sú nimi: Hľadanie, Dobrodružstvo, Prenasledovanie, Záchrana, Únik, Pomsta, Hádanka, Rivalita, Smoliar, Pokušenie, Metamorfóza, Transformácia, Dozrievanie, Láska, Zakázaná láska, Obetovanie, Objavenie, Úbohý prebytok, Vzostup a Zostup. 


\section{Extrakcia dát}
\label{webscraping}

Dáta sú nevyhnutnou súčasťou každého výskumu, či už to je akademický, marketingový alebo vedecký. Ľudia chcú zbierať a analyzovať údaje z viacerých webových stránok. Rôzne webové stránky, ktoré patria do konkrétnej kategórie zobrazuje informácie v rôznych formátoch. Údaje môžu byť rozložené na viacerých stránkach a v rôznych sekciách. Väčšina webových stránok neumožňuje uložiť kópiu údajov, zobrazených na ich webových stránkach do vášho miestneho úložiska. \textit{Web Scraping} je technikou extrakcie neštruktúrovaných údajov z webových stránok a taktiež transformáciou týchto údajov do štruktúrovaných údajov, ktoré možno uložiť do zrozumiteľnej štruktúry ako napr. tabuľka, databáza alebo súbor vo formáte CSV. 

Proces získavania údajov z internetu možno rozdeliť do dvoch po sebe nasledujúcich krokov; získavanie webových zdrojov a následné extrahovanie požadovaných informácií zo získaných údajov. Webové údaje sa bežne extrahujú pomocou protokolu HTTP (Hypertext Transfer Protocol) alebo cez web prehliadač. To sa buď vykonáva manuálne pomocou užívateľa alebo automaticky robotom alebo webovým prehliadačom. Konkrétne, program začína vytvorením HTTP požiadaviek na získanie zdrojov z cieľovej webovej stránky. Po úspešnom prijatí a spracovaní žiadosti cieľovou webovou stránkou sa požadovaný zdroj získa z webovej lokality a potom sa odošle späť do programu. Zdroj môže byť vo viacerých formátoch, ako sú webové stránky vytvorené z HTML, dátové kanály vo formáte XML alebo JSON alebo multimediálne dáta, akými sú obrázky, audio alebo video súbory. Po stiahnutí webových údajov proces extrakcie pokračuje v analýze, preformátovaní a usporiadaní údajov štruktúrovaným spôsobom. 

Vzhľadom na to, že sa na internete neustále generuje obrovské množstvo heterogénnych údajov, je web scraping široko uznávaný ako efektívna a výkonná technika na zber veľkých dát. 

Aj keď je web scraping účinnou technikou pri zhromažďovaní veľkých súborov údajov, je taktiež veľmi kontroverznou a môže vyvolať právne otázky súvisiace s autorskými právami a zmluvnými podmienkami. V rámci osobného použitia sa jedná o legálne využitie,  problém však nastáva v prípade komerčného využitia. Takisto, ak takýto program posiela žiadosti o získavanie údajov príliš často, je to funkčne ekvivalentné útoku odmietnutia služby (DoS -- Denial-of-Service), pri ktorom môže byť vlastníkovi odmietnutý vstup a môže byť zodpovedný za vzniknuté škody podľa, pretože vlastník webovej aplikácie má majetkovú účasť na fyzickom webovom serveri, ktorý je hostiteľom aplikácie.

Táto podkapitola vychádza z publikácií \cite{Zhao:2017} a \cite{Sirisuriya:2015}.


\section{Spracovanie prirodzeného jazyka}

Spracovanie prirodzeného jazyka (NLP -- angl. Natural Language Processing ) je počítačový prístup k analýze textu a je založený na súbore teórií aj na súbore technológií. Je to veľmi aktívna oblasť výskumu a vývoja v dnešnej dobe. NLP možno definovať asi nasledovne: Spracovanie prirodzeného jazyka je teoreticky motivované rozpätie výpočtových techník na analýzu a reprezentáciu prirodzene sa vyskytujúcich textov na jednej alebo viacerých úrovniach lingvistickej analýzy s cieľom dosiahnuť podobnosť s človekom pri spracovaní jazyka pre celý rad úloh alebo aplikácií.

Viaceré prvky tejto definície možno podrobnejšie rozviesť. Existuje viacero metód resp. techník, z ktorých si vybrať na vykonanie konkrétneho typu jazykovej analýzy. \uv{Prirodzene sa vyskytujúce texty} môžu byť akéhokoľvek jazyka, žánru a pod., jedinou požiadavkou je, aby boli v jazyku, ktorý používajú ľudia na komunikáciu medzi sebou. Analyzovaný text by tiež nemal byť špecifický vytvorený na účely analýzy, ale získaný zo skutočných použití. Pojem \uv{úrovne lingvistickej analýzy} odkazuje na skutočnosť, že existuje viacero typov jazykového spracovania, o ktorých je známe, že ľudia používajú pre pochopenie jazyka. NLP sa považuje za vnútornú disciplínu Umelej inteligencie (AI -- angl. Artificial Intelligence ), keďže NLP sa snaží o výsledky podobné človeku, je vhodné považovať NLP za disciplínu AI.

Cieľom NLP, ako je uvedené vyššie, je dosiahnuť spracovanie ľudského jazyka. Výber slova \uv{spracovanie} je veľmi zámerný a nemal by sa nahradiť výrazom \uv{pochopenie}. Oblasť NLP bola pôvodne označovaná ako Porozumenie prirodzeného jazyka (NLU -- angl. Natural Language Understanding ) v začiatkoch AI, a keďže dodnes nebol jazyk skutočne \uv{pochopený}, tak sa NLU považuje za cieľ NLP. 

Úplný NLU systém by bol schopný:

\begin{enumerate}
    \item \textbf{Parafrázovať vstupný text}
    \item \textbf{Preložiť text do iného jazyka}
    \item \textbf{Odpovedať na otázky z textu}
    \item \textbf{Vyvodzovať závery z textu}
\end{enumerate}

Zatiaľ čo NLP urobilo vážne zásahy do dosiahnutia cieľov 1 až 3, skutočnosť, že NLP systémy nedokážu samy o sebe vyvodzovať závery z textu, cieľom NLU stále zostáva NLP \cite{Liddy:2001} .

\section{Klasifikácia}
\label{klasifikacia}

Námety pre túto kapitolu vychádzali z \cite{Herrera:2016}. Klasifikácia (classification) je jednou z najpopulárnejších tém Spracovania prirodzeného jazyka a Hĺbkovej analýzy dát (Data Mining). Je to zvyčajne prediktívna úloha vedená pomocou techník učenia pod dohľadom (supervised learning). Klasifikácia má za cieľ naučiť sa z \textit{označkovaných} vzorov model schopný predpovedať značky (labels) pre budúce, nikdy predtým nevidené, ukážky údajov.

Sada atribútov v súbore údajov klasifikácie (classification dataset) je rozdelená do dvoch podmnožín. Tá prvá obsahuje vstupné vlastnosti (features), premenné, ktoré budú fungovať ako prediktory. Druhá podmnožina obsahuje výstupné atribúty, takzvané \textit{značky} (labels), ktoré sú priradené pre každú inštanciu. Klasifikačné algoritmy indukujú model analyzujúci koreláciu medzi vstupnými vlastnosťami a výstupnými značkami. Keď sa získa natrénovaný model, môže byť použitý na spracovanie množiny vstupných vlastností nových vzoriek údajov a tým získať predikciu značiek. V závislosti od povahy druhej podmnožiny atribútov, ktorá obsahuje značky, možno identifikovať niekoľko druhov klasifikačných problémov, v závislosti od počtu výstupov a ich typov. 

Medzi základné patrí: 
\begin{itemize}
    \item \textbf{Binárna klasifikácia} (Binary Classification) Toto je najjednoduchší klasifikačný problém, ktorému možno čeliť. Inštancie v binárnej dátovej sade majú iba jeden výstupný atribút a môže mať iba dve rôzne hodnoty. Tieto sú zvyčajne známe ako pozitívne a negatívne, ale možno ich interpretovať aj ako pravda a nepravda, 1 a 0 alebo akákoľvek iná kombinácia dvoch hodnôt. Klasický príklad tejto  úlohy je filtrovanie spamu, pri ktorom sa klasifikátor učí zo správ obsah, ktorý možno považovať za spam.
    
    \item \textbf{Viac-triedna klasifikácia} (Multi-class Classification) Viac-triedna dátová sada má tiež iba jeden výstupný atribút, ako binárna klasifikácia, ale môže obsahovať ktorúkoľvek z určitého súboru preddefinovaných hodnôt. Vo viac-triednej klasifikácií sa \textit{značky} nazývajú \textit{triedy} (class). Význam každého z týchto tried a samotná hodnota sú špecifické pre každú aplikáciu, súbor tried je však konečný a diskrétny. Jedným z najznámejších príkladov klasifikácie viacerých tried je identifikácia druhov dúhovky, kde sa klasifikátor učí, ako klasifikovať nové inštancie do zodpovedajúcej rodiny (triedy). Mnoho viac-triednych klasifikačných algoritmov závisí na binarizácií, metóda, ktorá iteratívne trénuje binárny klasifikátor pre každú triedu zvlášť. Viac-triednu klasifikáciu možno považovať za zovšeobecnenie binárnej klasifikácie. Výstup je len jeden, ale môže nadobudnúť akúkoľvek hodnotu, zatiaľ čo v binárnom prípade je obmedzený na podmnožinu dvoch hodnôt.
    
    \item \textbf{Viac-značková klasifikácia} (Multi-label Classification) Na rozdiel od dvoch predchádzajúcich klasifikačných modelov, vo viac-značkovej klasifikácií má každá z inštancií údajov priradený vektor výstupov, nie iba jednu hodnotu. Dĺžka tohto vektora je pevná a má dĺžku podľa počtu značiek v dátovej sade. Každý prvok vektora je binárna hodnota označujúca, či príslušná značka je alebo nie je relevantná pre vzorku. Aktívnych môže byť niekoľko značiek naraz. Viac-značková klasifikácia sa v súčasnosti používa v mnohých oblastiach, z ktorých väčšina súvisí na automatické označovanie zdrojov zo sociálnych médií, akými sú obrázky, hudba, video, správy, či blogové príspevky. Algoritmy použité na túto úlohu musia byť schopné vytvoriť niekoľko predpovedí naraz, či už ide o transformáciu pôvodných dátových sád alebo ich prispôsobenie na existujúce binárne/viac-triedne klasifikačné algoritmy.
\end{itemize}


\section{Klasifikačné metódy}
Kapitoly týkajúce sa klasifikačných metód sú prevzaté z publikácie \cite{Li:2021}. V ére informačnej explózie môže byť zdĺhavé a náročné spracovávať a klasifikovať veľké množstvo textových údajov manuálne. Okrem toho môže byť presnosť manuálnej klasifikácie textu ovplyvnená ľudskými faktormi, akými sú únava a neodbornosť. Je preto žiaduce použiť metódy strojového učenia na automatizáciu procesu klasifikácie textu, aby boli výsledky spoľahlivejšie a menej subjektívne. Okrem toho to môže tiež pomôcť zvýšiť efektivitu vyhľadávania informácií a zmierniť problém informačného preťaženia.

Textové údaje sa líšia od číselných, obrazových alebo signálových dát, vyžadujú NLP   techniky pre ich spracovanie. Prvým dôležitým krokom je predspracovanie textových údajov
pre model. Tradičné modely zvyčajne potrebujú získať dobré vlastnosti (features) umelými metódami a potom ich klasifikovať pomocou klasických algoritmov strojového učenia. Preto účinnosť týchto metóda je do značnej miery obmedzená extrakciou vlastností (feature extraction). Preto väčšina výskumných prác zameraných na klasifikáciu textu sú zamerané na hlboké neurónové siete, čo sú prístupy založené na údajoch (data-driven approaches) s vysokou výpočtovou náročnosťou.

Klasifikáciou textu sa myslí extrahovanie prvkov z nespracovaných textových údajov a predpovedanie kategórie textových údajov na základe takýchto vlastnosti (features). Množstvo modelov bolo navrhnutých za posledných niekoľko desaťročí na klasifikáciu textu. Z tradičných modelov, Naïve Bayes (NB) bol prvým použitým modelom na túto úloha. Potom sa používajú generické klasifikačné modely, ako napríklad K-Nearest Neighbor (KNN), Support Vector Machine (SVM) a Random Forest (RF). V poslednej dobe eXtreme Gradient Boosting (XGBoost) a Light Gradient Boosting Machine (LightGBM) majú potenciál poskytnúť vynikajúci výkon. Modely hlbokého učenia takisto išli veľmi do popredia, odkedy bola použitá konvolučná neurónová sieť po prvý krát na klasifikáciu textu. Aj keď nie je špeciálne navrhnutý na prácu s textom, je Bidirectional Encoder Representation from Transformers (BERT) široko používaný pri návrhu modelov pre klasifikáciu textu, vzhľadom na jeho efektivitu vo viacerých dátových sadách zameraných na textovú klasifikáciu.

\subsection*{Naïve Bayes}
Naïve Bayes (NB) je najjednoduchší a najrozšírenejší model založený na použití Bayesovho teorému. Algoritmus NB primárne využíva podmienenú pravdepodobnosť. Výhodou NB je, že na odhad parametrov potrebných na klasifikáciu vyžaduje len malý počet tréningových dát. Parametre NB sú menej citlivé na chýbajúce údaje a algoritmus je jednoduchý. Predpokladá však, že vlastnosti sú na sebe nezávislé. Keď počet vlastnosti je veľký, alebo korelácia medzi vlastnosťami je významná, výkon NB klesá. Napriek \uv{naivnému} dizajnu a zjednodušeným predpokladom je NB široko používaný aj v zložitých problémoch.

\subsection*{K-najbližších susedov}
Jadrom algoritmu k-najbližších susedov (angl. KNN -- K-Nearest Neighbors) je klasifikácia neoznačenej vzorky nájdením kategórie s najväčším počtom vzoriek na \textit{k} najbližších vzorkách. Je to jednoduchý klasifikátor bez nutnosti vytvárania modelu a môže znížiť zložitosť pomocou jednoduchého procesu získavania KNN. Avšak v dôsledku pozitívnej korelácie medzi časovou/priestorovou zložitosťou modelu a množstvom údajov, je algoritmus KNN na rozsiahlych dátových sadách nezvyčajne pomalý. KNN závisí hlavne od okolitých susedných vzoriek a pre dátové sady s väčším prekrytím tried  je vhodnejší ako iné metódy.

\subsection*{Support Vector Machine}
Prístupy založené na SVM menia klasifikáciu textu na viaceré úlohy binárnej klasifikácie. SVM sa snaží vytvárať optimálnu nadrovinu vo vektorovom priestore pre maximalizáciu vzdialenosti medzi triedami, a určiť vzdialenosť hranice kategórie v smere kolmom na nadrovinu čo najväčšiu, čo bude mať za následok nižšiu chybovosť klasifikácie. Využíva predchádzajúce znalosti na vytvorenie vhodnejšej štruktúry a rýchlejšie štúdium. SVM dokáže vyriešiť vysokorozmerné a nelineárne problémy. Má vysokú generalizačnú schopnosť, ale je citlivý na chýbajúce údaje.

\subsection*{Rozhodovacie stromy}
Rozhodovacie stromy (DT -- Decision Trees) sú metódy učenia s učiteľom stromovej štruktúry a sú konštruovaný rekurzívne, odrážajú myšlienku \textit{rozdeľuj a panuj}. Rozhodovacie stromy môžu byť všeobecne rozdelené do dvoch odlišných etáp: stavba stromov a prerezávanie stromov. Začína sa na koreňovom uzly kde testuje vzorky údajov, a rozdeľuje dátovú sadu do rozdielnych podmnožín podľa rôznych výsledkov. Podmnožiny dátovej sady tvoria synovské uzly a každý listový uzol v rozhodovacom strome predstavuje kategóriu. Konštrukcia rozhodovacieho stromu má určiť koreláciu medzi triedami a atribútmi, ktoré sa ďalej využívajú na predpovedanie kategórie neznámych budúcich typov. DT je ľahké pochopiť a interpretovať. Z pozorovaného modelu je ľahké odvodiť zodpovedajúci logický výraz z vygenerovaného rozhodovacieho stromu.

\subsection*{Neurónové siete}
Hlboké neurónové siete pozostávajú z umelých neurónových sietí, ktoré simulujú ľudský mozog, aby sa automaticky učil vysokoúrovňové vlastnosti z údajov, ktoré dosahujú lepšie výsledky ako tradičné modely spomenuté vyššie. Konvolučné neurnové siete (CNN -- Convolutional Neural Networks ) môže súčasne aplikovať konvolúcie definované rôznymi jadrami na viaceré časti sekvencie. Preto sa CNN používajú na mnohé úlohy NLP vrátane klasifikácie textu. Pre klasifikáciu textu sa vyžaduje, aby bol text reprezentovaný ako vektor. Najskôr sú všetky vektory slov vstupného textu spojené do matice. Matica sa potom privádza do konvolučnej vrstvy, ktorá obsahuje niekoľko filtrov s rôznymi rozmermi. Nakoniec výsledok konvolučnej vrstvy prechádza cez rozhodovaciu vrstva a zreťazí všetky výsledky, aby sa získala konečná vektorová reprezentácia, ktorá určuje výslednú triedu. 

Hlboké učenie pozostáva z viacerých skrytých vrstiev v neurónovej sieti s vyššou úrovňou zložitosti a môže byť trénovaný na neštruktúrovaných dátach. Hlboké učenie sa dokáže naučiť jazykové vlastnosti a dokáže zvládať aj abstraktnejšie jazykové prvky založené na slovách a vektoroch na vysokej úrovni. Architektúra hlbokého učenia sa vie naučiť reprezentovať vlastnosti priamo zo vstupu bez príliš veľkého manuálneho zásahu a predchádzajúcich znalostí. Technológia hlbokého učenia je však metódou založenou na dátach, ktorá si vyžaduje obrovské množstvo údajov na dosiahnutie vysokého výkonu. 

\section{Transformer}

Transformer \cite{Vaswani:2017} je prominentný model hlbokého učenia, ktorý je široko používaný v rôznych oblastiach, ako napr. NLP, počítačové videnie alebo spracovanie reči.
Transformer bol pôvodne navrhnutý ako \textit{Sequence-to-Sequence} model pre strojový preklad. Sequence-to-Sequence (alebo Seq2Seq) je neurónová sieť, ktorá transformuje danú sekvenciu prvkov, ako napríklad sekvenciu slov vo vete, na inú sekvenciu. Modely Seq2Seq pozostávajú z kodéra a dekodéra. Kóder vezme vstupnú sekvenciu a namapuje ju do priestoru vyššej dimenzie (n-rozmerný vektor). Tento abstraktný vektor sa privedie do dekodéra, ktorý ho zmení na výstupnú sekvenciu. Výstupná sekvencia môže byť v inom jazyku, symboloch, kópii vstupu atď.

\textit{Čistý} Transformer takiso teda pozostáva z kodéra a dekodéra, z ktorých každý z nich je zložený z \textit{n} rovnakých blokov, ktoré je možné na seba viackrát naskladať, čo je na obrázku \ref{transformer} popísané pomocou \textit{Nx}. Enkodér je vľavo a dekodér vpravo. Vidíme, že moduly pozostávajú hlavne z vrstiev \textit{Multi-Head Attention} a \textit{Feed Forward}.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.8\textwidth]{obrazky-figures/Transformer.png}
	\caption{Transformer -- architektúra modelu \cite{Vaswani:2017}.}
	\label{transformer}
\end{figure}

Pri Transformeroch sa stretávame s pojmom: \textit{Pozornosť}. Model si musí pamätať, ako sa sekvencie vkladajú do modelu, je nutné teda nejako dať každému slovu v sekvencii relatívnu polohu, pretože sekvencia závisí od poradia jej prvkov. Tieto pozície sa pridávajú do n-rozmerného vektora každého slova. V transformeroch sa toto nazýva \textit{mechanizmus pozornosti} (angl. Attention-mechanism). Mechanizmus pozornosti sa pozerá na vstupnú sekvenciu a v každom kroku rozhoduje, ktoré ďalšie časti sekvencie sú dôležité.

Inými slovami, pre každý vstup, ktorý kodér načíta, mechanizmus pozornosti berie do úvahy niekoľko ďalších vstupov súčasne a rozhoduje, ktoré z nich sú dôležité, priradením rôznych váh týmto vstupom. Dekodér potom vezme ako vstup zakódovanú vetu a váhy poskytnuté mechanizmom pozornosti.

Funkciu pozornosti možno opísať ako mapovanie dotazu (Q) a dvojice kľúč (K) – hodnota (V) na výstup, kde dotazy, kľúče, hodnoty a výstup sú všetko vektory. Výstup sa vypočíta ako vážený súčet hodnôt, kde váha priradená každej hodnote je vypočítaná funkciou kompatibility dotazu s príslušným kľúčom. Vstup pozostáva z dotazov a kľúčov dimenzie \(d_{k}\).
Mechanizmus pozornosti možno popísať rovnicou \eqref{rovnicaTransformer}: 

\begin{equation}
	Attention(Q, K, V)=  softmax(\dfrac{QK^{T}}{\sqrt{d_{k}}})V \label{rovnicaTransformer}
\end{equation}

Q je matica, ktorá obsahuje dotaz (vektorová reprezentácia jedného slova v sekvencii), K sú všetky kľúče (vektorové reprezentácie všetkých slov v sekvencii) a V sú hodnoty, ktoré sú opäť vektorové reprezentácie všetkých slov v sekvencií.

Váhy sú definované tým, ako je každé slovo v sekvencii (Q) ovplyvnené všetkými ostatnými slovami v sekvencii (K). Okrem toho je na váhy aplikovaná funkcia \textit{SoftMax}, aby mali rozdelenie medzi 0 a 1. Tieto váhy sa potom aplikujú na všetky slová v sekvencii (V).

Architektúra transformerov používa komplexnejšiu \textit{Multi-Head attention} vrstvu, ktorá paralelizuje tento mechanizmus a umožňuje to systému učiť sa z rôznych reprezentácií Q, K a V. 

Neskoršie práce ukazujú, že predtrénované modely založené na transformeroch môžu dosiahnuť \textit{state-of the-art performace} pri rôznych úlohách. V dôsledku toho sa Transformer stal \textit{go-to} architektúrou v NLP. \cite{Tianyang:2021} \cite{Allard:2019}

\section{BERT} \label{bert}

BERT \cite{Devlin:2018} (Bidirectional Encoder Representations from Transformers) je
zástupca z rodiny transformerov. 

Kľúčovou technickou inováciou BERT je aplikácia obojsmerného učenia Transformera. To je v kontraste s predchádzajúcimi snahami, ktoré sa zaoberali textovou sekvenciou buď zľava doprava, alebo kombinovaným učením zľava doprava a sprava doľava. Výsledky ukazujú, že jazykový model, ktorý je trénovaný obojsmerne, môže mať hlbší zmysel pre jazykový kontext a tok ako jednosmerné jazykové modely. V článku vedci podrobne opisujú novú techniky, ktoré umožňujú obojsmerný tréning v modeloch, v ktorých to bolo predtým nemožné.

BERT využíva Transformer, mechanizmus pozornosti, ktorý sa učí kontextové vzťahy medzi slovami  v texte. Vo svojej základnej podobe obsahuje Transformer dva samostatné mechanizmy – kóder, ktorý číta textový vstup, a dekodér, ktorý vytvára predpoveď pre danú úlohu. Keďže cieľom BERT je vygenerovať jazykový model, je potrebný iba kóder. Na rozdiel od smerových modelov (directional models), ktoré čítajú textový vstup postupne (zľava doprava alebo sprava doľava), kodér Transformera načíta celú sekvenciu slov naraz. Preto sa považuje za obojsmerný, aj keď presnejšie by bolo povedať, že je nesmerný (non-directional). Táto charakteristika umožňuje modelu naučiť sa kontext slova na základe celého jeho okolia (vľavo a vpravo od slova).

Pri trénovaní jazykových modelov existuje výzva, ako definovať cieľ predikcie. Mnoho modelov predpovedá ďalšie slovo v sekvencií, čo je smerový prístup (directional approach), ktorý vo svojej podstate obmedzuje kontextové učenie. Na prekonanie tejto výzvy používa BERT dve tréningové stratégie:
\begin{itemize}
    \item \textbf{Maskovaný jazykový model}  (MLM -- Masked Language Model )  Nanešťastie, štandardné  jazykové modely môžu byť len trénované zľava doprava alebo sprava doľava, pretože obojsmerné by každému slovu umožnili nepriamo „vidieť samého seba“ a model by mohol triviálne predpovedať cieľové slovo vo viacvrstvovom kontexte. Preto sa jednoducho maskuje určité percento vstupných tokenov a potom sa tieto maskované tokeny predpovedajú. Tento postup sa označuje ako MLM, a BERT je trénovaný tak, že je náhodne maskovaných asi 15 \% všetkých tokenov. Hoci táto stratégia umožňuje získať obojsmerný pred-trénovaný model, nevýhodou je nesúlad medzi pred-tréningom (pre-training) a dolaďovaním (fine-tuning), pretože maskované tokeny sa počas dolaďovania nevyskytujú.
    
    \item \textbf{Predpoveď ďalšej vety} (Next Sentence Prediction -- NSP) Mnohé dôležité nadväzujúce úlohy (downstream tasks) sú založené na pochopení vzťahu medzi dvoma vetami, ktorý nie je priamo zachytený jazykovým modelovaním. Aby bolo možné trénovanie modelu, ktorý rozumie väzbám viet, používa BERT binarizovanú NSP úlohu, ktorú možno triviálne vygenerovať z akéhokoľvek jednojazyčného korpusu. V tréningovom procese model BERT dostáva páry viet ako vstup a učí sa predpovedať, či druhá veta v páre je vetou nasledujúcou v pôvodnom dokumente. Počas tréningu tvorí 50 \% vstupov dvojica, kde je druhá veta vetou nasledujúcou v pôvodnom dokumente, zatiaľ čo v ostatných 50 \% je ako druhá veta zvolená náhodná veta z korpusu. Predpokladom je, že náhodná veta bude odpojená od prvej vety.
\end{itemize}

Pri trénovaní modelu BERT sa MLM a NSP trénujú spoločne s cieľom minimalizovať kombinovanú stratovú funkciu (loss function) týchto dvoch stratégií. \cite{Horev:2019} \cite{Sun:2019} 

\subsection{Fine-tuning} \label{finetuning}

Použitie BERT na konkrétnu úlohu je pomerne jednoduché. BERT možno použiť na širokú škálu jazykových úloh, pričom do základného modelu stačí pridať iba malú vrstvu. Dolaďovanie (fine-tuning) je proces adaptovania BERT na konkrétnu nadväzujúcu úlohu (downstream task), či už je vstup jedno-textový alebo sa jedná o textové páry. Pre každú úlohu stačí zapojiť vstupy a výstupy špecifické pre danú úlohu do BERT a doladiť všetky parametre end-to-end. Na vstupe namiesto vety A a vety B z pred-tréningu je pri klasifikácií pár text-značky. V porovnaní s pred-tréningom je dolaďovanie relatívne lacné, čo sa týka času. 
Pre vhodné doladenie BERT na konkrétnu úlohu je nutné okrem iného aj správne nastavenie hyperparamterov alebo pridanie extra vrstvy. Pre viac-značkovú klasifikáciu (multi-label) je nutné pridať vrstvu s aktivačnou funkciou sigmoid. Často sa používa softmax aktivačná funckia vo viac-triednych  úlohách (multi-class), čo je predvolená aktivačná funkcia tradičného BERT. Funkcia softmax však nie je vhodná pre úlohy s viacerými značkami, pretože súčet pravdepodobností výstupu funkcie softmax je 1. To sa nehodí v situáciách, keď sa môže byť prítomných viacero značiek súčasne.  Výstupy sigmoidnej funkcie sa pohybujú od 0 do 1, ktoré sú na sebe nezávislé a predstavujú pravdepodobnosť pre každú značku zvlášť. Súčet výstupov sigmoidnej funkcie nie je 1, takže viac ako jedna značka má možnosť získať skóre nad určitú hranicu prahu (threshold). Takto možno každú značku klasifikovať na 0 a 1 podľa hodnoty prahu.
\cite{Devlin:2018} \cite{Sun:2019} \cite{Tang:2020}

\subsection{Spracovanie dlhých reťazcov} \label{dlhe}

Ďalším faktorom pri dolaďovaní BERT na klasifikáciu textu je dĺžka vstupnej sekvencie a spracovanie dlhých reťazcov, keďže maximálna dĺžka vstupu BERT je 512 tokenov.Pripadajú do úvahy nasledujúce spôsoby zaoberajúce sa dlhými reťazcami.

\textbf{Metódy skrátenia} Zvyčajne sú kľúčové informácie článku na začiatku a na konci. Preto možno použiť tri rôzne metódy skrátenia textu.
\begin{enumerate}
    \item Iba úvodných 510 tokenov\footnote{Treba odpočítať tokeny [CLS] a [SEP].}
    \item Iba konečných 510 tokenov
    \item 128 tokenov z úvodu a 382 tokenov z konca textu
\end{enumerate}

\textbf{Hierarchické metódy} Vstupný text je najskôr rozdelený na k = L/510 frakcií, ktoré sa privádzajú do BERT s cieľom získať zastúpenie k textových zlomkov. Potom sú použité metódy \textit{mean pooling}, \textit{max pooling} a seba-pozornosť na kombináciu reprezentácie všetkých zlomkov.\cite{Sun:2019}

\textbf{Longformer} \cite{Beltagy:2020} Ďalšou možnosťou ako spracovávať dlhšie reťazce je použiť upravenú verziu BERT, s názvom Longformer, ktorý dokáže spracovávať vstup o veľkosti 4096 tokenov v relatívne krátkom čase.


\section{Metriky vyhodnocovania} \label{metriky}

Táto podkapitola je prebraná z \cite{Herrera:2016}. Výstup akéhokoľvek klasifikátora s viacerými značkami pozostáva z predpovedaného vektora značiek pre každú testovaciu inštanciu. Pri práci v tradičnom scenári s iba jednou triedou ako výstupom,  predpoveď môže byť správna alebo nesprávna, naproti tomu predpovede viacerých značiek môžu byť úplne správne, čiastočne správne/nesprávne (v rôznych stupňoch) alebo úplne nesprávne.
Použitie rovnakých metrík používaných v tradičnej klasifikácii je možné, ale zvyčajne prehnane prísne. To je dôvod na použitie špecifických hodnotiacich metrík, kde sa berú do úvahy aj prípady medzi týmito dvoma extrémami.
V súčasnosti je v literatúre definovaných viac ako dvadsať rôznych výkonnostných metrík pre viac-značkovú klasifikáciu. Všetky metriky vyhodnocovania viacerých značiek možno zoskupiť podľa dvoch kritérií:
\begin{itemize}
\item \textbf{Podľa toho ako sa  predpoveď vypočítava}: Meranie môže byť vykonané inštanciou alebo pomocou
značiek, čím sa získajú dve rôzne skupiny metrík:
    \begin{itemize}
    \item \textbf{Metriky založené na príkladoch}: Tieto metriky sa počítajú samostatne pre každú inštanciu a potom sú  spriemerované počtom vzoriek.
    \item \textbf{Metriky založené na značkách}: Na rozdiel od predchádzajúcej skupiny metriky založené na značkách sa vypočítajú nezávisle pre každú značku pred ich spriemerovaním. Pritom možno použiť dve rôzne stratégie:
        \begin{itemize}
        \item \textbf{Makro-priemerovanie}: Metrika sa vypočítava individuálne pre každú značku a
        výsledok je spriemerovaný počtom značiek.
        \item \textbf{Mikro-priemerovanie}: Počítadlá trafených a netrafených predpovedí pre každú značku sú najskôr agregované a potom sa metrika vypočíta iba raz.
        \end{itemize}
    \end{itemize}
\item \textbf{Podľa toho ako sa výsledok sprostredkuje}: Výstup produkovaný viac-značkovým klasifikátorom môže byť binárna bipartícia značiek alebo poradie značiek. Niektoré z nich poskytujú oboje výsledky.
    \begin{itemize}
    \item \textbf{Binárna bipartícia}: Binárne bipartícia je vektor označujúci 0 a 1, ktoré indikujú, že značka je relevantná pre spracovanú vzorku. Existujú metriky, ktoré fungujú nad týmito bipartíciami a počítajú počet skutočne pozitívných (angl. True Positive -- TP), skutočne negatívných (angl. True Negative -- TN), falošne pozitívných (angl. False Positive -- FP) a falošne negatívných (angl. False Negative -- FN) vzoriek.
    \item \textbf{Poradie značiek}: Výstupom je zoznam značiek zoradených podľa nejakej relevantnosti. Binárnu bipartíciu možno z tohoto poradia získať použitím prahu, zvyčajne daný samotným klasifikátorom. Existujú však metriky, ktoré namiesto toho pracujú s nespracovaným poradím na výpočet vyhodnotenia.
    \end{itemize}
\end{itemize}

\subsection*{Hammingova strata} 
Hammingova strata (angl. Hamming loss) je jednou z metrík založených na príkladoch, je pravdepodobne najbežnejšie používanou metrikou viac-značkovej klasifikácie, asi aj pretože je ľahké ju vypočítať ako možno vidieť v rovnici \eqref{rovnica1}. Operátor \(\bigtriangleup\) vráti symetrický rozdiel medzi \(Y_{i}\), reálnym vektorom značiek i-tej inštancie a tým predpovedaným \(Z_{i}\). Operátor \(|r|\) počíta počet 1 v tomto rozdiele, inými slovami počet nesprávnych predpovedí. Celkový počet chýb v \(n\) inštanciách sa agreguje a potom normalizuje počtom značiek \(k\) a počtom inštancií.

\subsection*{Presnosť} 
Narozdiel od anglického jazyka, kde na slovo \textit{presnosť} majú 2 slová \textit{Accuracy} a \textit{Precision}, v našich jazykoch nanešťastie nevieme tieto dve slová odlíšiť, no predsa je medzi nimi rozdiel, preto v nasledujúcich odstavcoch budú použité dané anglické výrazy.  

Vo viac-značkovej oblasti je \textit{Accuracy} definovaná ako \eqref{rovnica2} pomer medzi hodnotami počtu správne predpovedaných značiek a celkového počtu značiek v oboch vektoroch. Metrika je počítaná pre každú inštanciu a potom je spriemerovaná ako všetky metriky založené na príkladoch.

\textit{Precision} \eqref{rovnica3}, naproti tomu, sa považuje za jednu z intuitívnejších metrík na hodnotenie viac-značkových klasifikátorov. Vypočíta sa ako podiel medzi počtom skutočne pozitívnych značiek a celkovým počtom pozitívnych značiek. Teda môže byť interpretovaná ako percento predpovedaných značiek, ktoré sú skutočne relevantné pre danú inštanciu. Táto metrika sa zvyčajne používa v spojení s funkciou \textit{Recall} (v tomto prípade je preklad ťažko interpretovať) \eqref{rovnica4}, ktorá vracia percento správne predpovedaných značiek spomedzi všetkých skutočne relevantných značiek, teda pomer správnych značiek je výstupom klasifikátora.

\subsection*{F-skóre}
Spoločné používanie \textit{Precision} a \textit{Recall} je tak bežné, že je definovaná metrika, ktorá ich kombinuje. Je známa ako F-skóre (angl. F-measure/ F-score) \eqref{rovnica5} a vypočíta sa ako harmonický priemer týchto dvoch. Týmto spôsobom je vyvážená miera toho, koľko relevantných značiek je predpovedaných a koľko predpovedaných značiek je relevantných.

\subsection*{Priemerná presnosť}
Všetky metriky založené na príkladoch popísané vyššie fungujú cez binárnu bipartíciu značiek, takže potrebujú sadu značiek ako výstup z klasifikátora. Naproti tomu, nasledujúca metrika potrebujú poradie značiek, takže buď stupeň spoľahlivosti alebo pravdepodobnosť príslušnosti každej zo značiek je potrebná na jej výpočet.

Metrika priemerná presnosť (angl. Average precision) \eqref{rovnica6} určuje pre každú značku v inštancií, podiel relevantných značiek, ktoré sú v predpokladanom poradí nad ňou. Cieľom tejto metriky je zistiť, koľko pozícií treba v priemere skontrolovať, predtým, než sa nájde nerelevantné označenie. Čím väčšia je hodnota tejto metriky, tým lepší je výkon klasifikátora.
V rovnici \eqref{rovnica6} je \(rank(x_{i},l)\) definovaná ako funkcia ktorá pre inštanciu \(x_{i}\) a príslušnú značku \(l \), ktorej poloha je známa, vráti stupeň spoľahlivosti.


\subsection*{Metriky založené na značkách}
Všetky výkonnostné metriky vymenované v predchádzajúcich častiach sa vyhodnocujú jednotlivo pre každú inštanciu a potom sú spriemerované počtom inštancií. Preto má každá vzorka údajov v konečnom výsledku rovnakú váhu. Na druhej strane, metriky založené na značkách možno vypočítať pomocou dvoch rôznych stratégií spriemerovania. Tieto sú zvyčajne známe ako makro-priemerovanie a mikro-priemerovanie. Ktorákoľvek z metrík získaných z binárnej bipartície, ako \textit{Precision}, \textit{Recall} či F-skóre je možné vypočítať pomocou týchto stratégií.

V prístupe makro-priemerovania \eqref{rovnica7} sa metrika vyhodnocuje raz za značku pomocou akumulovaného počítadlá a priemer sa potom získa vydelením počtom značiek. Takto je každej značke priradená rovnaká váha, či už je častá alebo zriedkavá. Naopak, stratégia mikro-priemerovania \eqref{rovnica8} najskôr pripočítava počítadlá pre všetky značky a potom vypočíta metriku iba raz. Preto prínos každej značky vo finále nie je rovnaký.


\begin{equation}
	HammingLoss =  \dfrac{1}{n} \dfrac{1}{k} \sum_{i=1}^{n} | Y_{i} \bigtriangleup Z_{i} | \label{rovnica1}
\end{equation}
\begin{equation}
	Accuracy =  \dfrac{1}{n}  \sum_{i=1}^{n} \dfrac{| Y_{i} \cap Z_{i} |} {| Y_{i} \cup Z_{i} |} = \dfrac{TP + TN}{TP + TN + FP + FN} \label{rovnica2}
\end{equation}
\begin{equation}
	Precision =  \dfrac{1}{n}  \sum_{i=1}^{n} \dfrac{| Y_{i} \cap Z_{i} |} {| Z_{i} |} = \dfrac{TP}{TP + FP} \label{rovnica3}
\end{equation}
\begin{equation}
	Recall =  \dfrac{1}{n}  \sum_{i=1}^{n} \dfrac{| Y_{i} \cap Z_{i} |} {| Y_{i} |} = \dfrac{TP}{TP + FN} \label{rovnica4}
\end{equation}
\begin{equation}
	\textit{F-score} =  2* \dfrac{Precision*Recall}{Precision+Recall} =  \dfrac{TP}{TP + \dfrac{1}{2} (FP + FN)} \label{rovnica5}
\end{equation}
\begin{equation}
	AveragePrecision = \dfrac{1}{n}  \sum_{i=1}^{n} \dfrac{1}{| Y_{i} |} \sum_{y \in Y_{i}} 
	\dfrac{| \{ y^{'}|rank(x_{i},y^{'}) \leq rank(x_{i},y), y^{'} \in  Y_{i} \}|} {rank(x_{i},y)} \label{rovnica6}
\end{equation}
\begin{equation}
	MacroMetric =  \dfrac{1}{k} \sum_{l \in L} EvalMetric(TP_{l},FP_{l},TN_{l},FN_{l})  \label{rovnica7}
\end{equation}
\begin{equation}
	MicroMetric =  EvalMetric( \sum_{l \in L} TP_{l}, \sum_{l \in L} FP_{l}, \sum_{l \in L} TN_{l}, \sum_{l \in L} FN_{l} )  \label{rovnica8}
\end{equation}


\noindent\(n\) = počet inštancií \newline
\(k\) = počet značiek  \newline
\(Y_{i}\) = reálny vektor značiek i-tej inštancie  \newline
\(Z_{i}\) = predpovedaný vektor značiek i-tej inštancie \newline
\(\bigtriangleup\) = symetrický rozdiel  \newline
\(|r|\) = počet nesprávnych predpovedí \newline
\(TP\) = True Positive \newline
\(TN\) = True Negative \newline
\(FP\) = False Positive \newline
\(FN\) = False Negative \newline
\(L\) = všetky značky v dátovej sade  \newline



\section{Metriky podobnosti} \label{podobnost}

Pre porovnanie dvoch vektorov a určenie ich podobnosti, existujú viaceré metriky. Tieto vektory môžu reprezentovať text, obraz a iné dáta a je možné teda takto určiť podobnosť medzi týmito dvoma vektormi. Metriky podobnosti fungujú na základe merania uhlu medzi týmito dvoma vektormi, aj keď sa jedná o viac-dimenzionálne vektory. 

Jedny zo základných metrík sú Pearsonov korelačný koeficient, Spearmanov korelačný koeficient a kosínusová podobnosť, ktoré sú základom pre analýzu údajov.

\begin{itemize}
    \item \textbf{Kosínusová podobnosť} Kosínusová podobnosť je štandardná metrika používaná pri získavaní informácií. Je to kosínus uhla medzi dvoma euklidovskými vektormi, a preto nie je ovplyvnený skalárnymi transformáciami v údajoch. Je definovaný nižšie v rovnici \eqref{rovnicaCosinus} pre vektory \(x\) a \(y\).
    
    \item \textbf{Pearsonov korelačný koeficient} Pearsonove a Spearmanove koeficienty merajú silu asociácie medzi dvoma premennými \(X\) a \(Y\) . Pearsonov koeficient, bežne označovaný ako \(\rho\), je definovaný ako kovariancia dvoch premenných delená súčinom ich príslušných štandardných odchýlok. \eqref{rovnicaPearson}
    
    \item \textbf{Spearmanov korelačný koeficient} Spearmanov koeficient sa získa aplikáciou Pearsonovho koeficientu na dáta transformované podľa poradia. Oba nie sú ovplyvnené lineárnymi transformáciami údajov. Z vektorov \(x\) a \(y\), respektíve premenných \(X\) a \(Y\), každý s dĺžkou \(n\), sa Spearmanov koeficient \(r_{x,y}\) získa odhadom kovariancie populácie a štandardných odchýlok od vzoriek, ako je definované v rovnici \eqref{rovnicaSpearman}. \(\bar{x}\) a \(\bar{y}\) tu označujú priemer vzoriek. \cite{Dongen:2012}
\end{itemize}

\begin{equation}
	\cos(\theta) =  \dfrac{\sum{x_{i}y_{i}}}{\sqrt{\sum{x_{i}^2}}\sqrt{\sum{y_{i}^2}}} \label{rovnicaCosinus}
\end{equation}

\begin{equation}
	\rho_{X,Y} =  \dfrac{cov(X,Y)}{\sigma_{X} \sigma_{Y}} \label{rovnicaPearson}
\end{equation}

\begin{equation}
	r_{x,y} =  \dfrac{\sum{(x_{i}-\bar{x})(y_{i}-\bar{y})}}{\sqrt{\sum{(x_{i}-\bar{x})^2}} \sqrt{\sum{(y_{i}-\bar{y})^2}}} \label{rovnicaSpearman}
\end{equation}


\chapter{Dáta} \label{data}
Dáta sú nevyhnutnou súčasťou každej dátovej analýzy a je rovnako dôležitá ich kvantita ako aj ich kvalita. V tejto kapitole sú popísané všetky dátové sady použité v tejto práci. V nasledujúcej sekcií je popísané získavanie a výber kľúčových dejových línií, tento dataset slúži ako hlavný trénovací dataset. Ďalej je popísaná populárna dátová sada z internetu obsahujúca zhrnutia kníh. Nakoniec sú predstavené dátové sady zo sociálnej siete Goodreads, ktoré boli vytvorené vrámci tejto práce.

\section{Dátová sada z IMDb} \label{imdbdata}
Veľmi dôležitou súčasťou klasifikácie dejov je zadefinovanie si, s akými kľúčovými dejovými líniami sa pracuje a vybrať teda konkrétne, ktoré sú to, určiť či ich je zopár, alebo stovky. Ako je napísané v kapitole \ref{kdl}, pohľady na toto sú rôzne. Rozhodol som sa rozšíriť prístup, ktorý bol zvolený v \cite{Tobias:1993}, kde je spomenutých 20 kľúčových dejových línií. Chcel som, aby konkrétne kľúčové dejové línie vypovedali niekedy aj trocha viac o príbehu ako jednoduché jednoslovné pomenovania v spomínanej knihe.

Možnosť označkovať si dáta ručne nepripadá do úvahy, lebo na učenie je potrebné kvantum dát, preto je nutné hľadať zdroje, ktoré ponúkajú takto označkované dáta. Možnosti nie je až tak veľa, no jednou vhodnou sú kľúčové slová z webu IMDb\footnote{https://www.imdb.com/}, kde ku najmä populárnym filmom a seriálom možno nájsť zhrnutia dejov a kľúčové slová. Jedinou nevýhodou je, že sa jedná o filmy a nie o knihy, no dej sa rovnako nachádza aj vo filme aj v knihe. Primárne sa práca zameriava na knihy no ako je aj v úvode a abstrakte spomenuté, môže sa jednať o akékoľvek zhrnutie deja. Tieto kľúčové slová hovoria o všetkých možných aspektoch, ktoré sa v danom diele nachádzajú. Pre konkrétne dielo môžu byť aj stovky kľúčových slov. Ak vo filme prší je kľúčovým slovom dážď, ak je vo filme dôležitý nejaký predmet alebo udalosť, tak je kľúčovým slovom práve to. Týkajú sa takisto aj témy, prostredia, žánru ale aj príbehu.

Tak som si teda vybral viac ako 100 kľúčových slov, týkajúcich sa deja spomedzi všetkých týchto kľúčových slov, a tie budú reprezentovať kľúčové dejové línie. Nachádzajú sa medzi nimi aj jednouché jednoslovné ako napr. \textit{love}, \textit{revenge}, \textit{escape}, \textit{racism} a pod., ale aj špecifickejšie ako \textit{time travel}, \textit{abuse of power}, \textit{one against many} alebo \textit{love triangle}. Takto spojené aj jednoduché aj zložitejšie môžu už dať dobrý obraz o tom, o čom príbeh je. Celý po experimentoch upravený zoznam je možné si prezrieť v prílohe \ref{priloha-kdl}. 

Tieto dáta boli získané zo serverov výskumnej skupiny KNOT, ktorá IMDb stránky už mala stiahnuté vrámci iných projektov. V rámci tejto práce bola z týchto HTML súborov extrahovaná dátová sada obsahujúca názvy filmov/seriálov, zhrnutia deja a kľúčové dejové línie. Táto dátová sada obsahuje 172 789 záznamov. Vzorku týchto dát sa nachádza v tabuľke \ref{imdb}.

\subsection*{Vzorka dát}

\begin{table}[hbt]
\centering
\caption{Vzorka dát z IMDb dátovej sady.}
\label{imdb}
\begin{tabular}{|c|c|
>{\centering\arraybackslash}m{7em}|
>{\centering\arraybackslash}m{7em}|}
\hline
IMDb ID & Movie/Series title & Plot keywords & Plot summary \\
\hline
2140373 & Saving Mr. Banks & loss of father, family relationships, death, flashback &  A doting father, Walter Elias Disney (Tom Hanks)...\\ 
\hline

\end{tabular}
\end{table}

\section{Dátová sada Booksummaries}
Okrem kľúčových dejových línií je nutné zozbierať aj knižné zhrnutia dejov. Jednou z voľne dostupných dátových sád je \textit{CMU Book Summary Dataset}\footnote{http://www.cs.cmu.edu/~dbamman/booksummaries.html}, ktorá obsahuje obsahuje zhrnutia dejov pre 16 559 kníh extrahovaných z Wikipédie spolu s metadátami z Freebase, vrátane autora knihy, názvu a žánrov. Ukážku týchto dát si možno pozrieť v tabuľke \ref{booksummaries}.

\subsection*{Vzorka dát}

\begin{table}[hbt]
\centering
\caption{Vzorka dát z Booksummaries.}
\label{booksummaries}
\begin{tabular}{|c|c|c|
>{\centering\arraybackslash}m{7em}|
>{\centering\arraybackslash}m{7em}|}
\hline
Wikipedia ID & Book title & Author & Book genres & Plot summary \\
\hline
620 & Animal Farm & George Orwell & Roman à clef, Satire, Children's literature, Speculative fiction, Fiction &  Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where...\\ 
\hline

\end{tabular}
\end{table}

\section{Dátová sada z Goodreads} \label{goodreadsdata}

Jednou z najväčších sociálnych sietí o knihách je určite Goodreads\footnote{https://www.goodreads.com/}, kde si užívatelia môžu prezerať viac než 60 miliónov kníh, zistiť si o nich základné údaje, písať k ním recenzie a veľa ďalšieho. Okrem iného obsahuje každá knižná stránka zopár užívateľských recenzií k danej knihe a krátky text opisujúci určitým spôsobom danú knihu. Niekedy sa jedná o citácie z knihy, niekedy o to čo iný povedali o tejto knihe, niekedy je to abstrakt a niekedy dokonca aj zhrnutie deja. Všetky tieto dáta boli pomocou web scrapingu \ref{webscraping} stiahnuté na servery výskumnej skupiny KNOT. Bol to proces veľmi zdĺhavý, keďže ako je spomenuté, knižných stránok je veľmi veľa. Sťahovanie trvalo vyše mesiaca. Cieľom bolo vytvoriť pravdepodobne najväčšiu dátovú sadu informácií o knihách a užívateľských recenzií o knihách vôbec. Všetky tieto dáta teda bolo nutné ďalej spracovať a odfiltrovať. Boli vybrané iba knihy, ktoré obsahujú viac ako 10 užívateľských recenzií, teda knihy aspoň trocha čítané, aby výsledná dátová sada bola prehľadnou a prínosnou, bez prebytočných dát. A z týchto knižných stránok boli extrahované iba dôležité informácie a boli tak vytvorené 2 dátové sady: o informáciach o knihe a o recenziách. Výsledné datasety obsahujú 23 748 648 recenzií a 922 935 informácií o knihe. V tabuľkách 
\ref{bookinfo} a \ref{reviewinfo} sa nachádzajú príklady z týchto dátových sád.

Nepýtal som si žiadne povolenie od stránky Goodreads na takéto sťahovanie a keďže oblasť extrakcie dát z webu je veľmi háklivou témou, tak tieto dátové sady samozrejme nebudú nikde zverejnené a sú určené len na študijné účely a výskumná skupina KNOT ich samozrejme môže ďalej využívať v ďalších projektoch.

\subsection*{Vzorka dát}

\begin{table}[hbt]
\centering
\caption{Vzorka dát z Goodreads datasetu informácií o knihe.}
\label{bookinfo}
\begin{tabular}{|c|c|c|c|c|}
\hline
Goodreads ID & Book title & Author & No. of Ratings & No. of Reviews  \\
\hline
18007564 & The Martian & Andy Weir & 931 685 & 77 600\\ 
\hline
\end{tabular}
\begin{tabular}{|c|c|c|}
\hline
Avg. Rating & Year & Description \\
\hline
4.4  & 2011 & Six days ago, astronaut Mark Watney became... \\ 
\hline
\end{tabular}
\end{table}

\begin{table}[hbt]
\centering
\caption{Vzorka dát z Goodreads datasetu recenzií.}
\label{reviewinfo}
\begin{tabular}{|c|c|c|c|c|}
\hline
Book ID & Book title & User ID  & Username & Rating (/5) \\
\hline
18007564 & The Martian & 25375513 & Rick Riordan & 5\\ 
\hline
\end{tabular}
\begin{tabular}{|c|c|c|}
\hline
Date & Has spoiler & Review \\
\hline
July 24, 2015  & False & Adult science thriller.  Love it, love it!...\\ 
\hline
\end{tabular}
\end{table}


\chapter{Návrh systému}
\label{navrh}

Táto kapitola sa venuje návrhu riešenia systému pre analýzu dejových línií. Pre návrh podobného systému sú alfou a omegou dáta. Je ním zvlášť venovaná kapitola a sú v nej popísané všetky dátové sady, s ktorými sa v práci pracuje. Ďalej je popísaný proces analýzy dát, kde je priblížené ako sa dá klasifikátor naučiť predikovať kľúčové dejové línie a ako tieto výsledky vyhodnocovať a interpetovať. Nakoniec sú zhrnuté ciele tejto práce a bližšie popísané čo sa chce touto prácou dokázať. 

\section{Motivácia}

Analýza dejových línií nie je oblasťou veľmi prebádanou, no existuje veľa prác a článkov, dokonca aj tutoriálov, o analýze žánrov. Ako je naznačené aj v úvode, v kľúčových dejových líniách \ref{kdl} je množstvo skrytého potenciálu, ktorý sa táto práca snaží priblížiť. Sú zaujímavou alternatívou k žánrom a vedia niekedy vypovedať viac o deji ako žánre. Pomocou nich by sa mohol v sociálnych sieťach definovať nový spôsob delenia obsahu. 

Oproti ostatným prácam je táto inou aj tým, že miesto častejšie používanej viac-triednej klasifikácie sa používa klasifikácia viac-značková (viď. \ref{klasifikacia}). Je to kvôli tomu, že kľúčových dejov sa môže v zhrnutí deja nachádzať viac než len jeden, čo opäť pridáva väčšiu hodnotu pri ich klasifikácií.

Práca sa zameriava na menej bežné, no nemenej dôležité a zaujímavé dejové línie a snaží sa analyzovať zhrnutia dejov a užívateľských recenzií v anglickom jazyku a následne predpovedať k nim kľúčové dejové línie. Ďalej je systém schopný porovnať dva deje na základe týchto kľúčových dejových línií a určiť tak či sú si diela, čo sa deja týka, podobné.

Bola aj snaha zozbierať čo najväčšie množstvo dát o knihách a k nim užívateľských recenzií, keďže takéto dátové sady sú väčšinou malé, alebo neposkytujú dostatok informácií. Preto bola vytvorená pravdepodobne najväčšia dátová sada informácií o knihách a k nim užívateľských recenzií v anglickom jazyku.

\section{Analýza dát}

Zo spracovanými dátami a vytvorenými dátovými sadami, je už možné tieto dáta ďalej analyzovať a prejsť k úlohe klasifikácie. Najlepšie výsledky dosahujú metódy založené na strojovom učení, a najmä tie založené na neurónových sieťach, preto je asi najvhodnejšie vybrať BERT \cite{Devlin:2018}, prípadne nejakú jeho variantu, keďže dominuje v rebríčkoch\footnote{http://nlpprogress.com/} viacerých úloh spracovania prirodzeného jazyka. Je nutné stiahnuť nejakú variantu BERTa a adaptovať ho na dáta, s ktorými bude pracovať. Bude sa teda jednať o \textit{fine-tuning} \ref{finetuning}, ktorému sa v tomto kontexte bude hovoriť tréning, učenie či ladenie. Pred samotným tréningom je nutné sa uistiť aby mal BERT v poslednej vrstve aktivačnú funkciu sigmoid, a nie softmax, pretože sa bude jednať o viac-značkovú klasifikáciu, a bez tohoto by na výstupe boli úplne iné hodnoty. Predtým, než sa model začne učiť je treba správne nastaviť parametre učenia, napr. rýchlosť učenia, hodnotiaca funkcia, po koľkých krokoch sa má model znova vyhodnotiť a pod. Budú sa takisto musieť využiť nejaké spôsoby pre spracovanie dlhých reťazcov \ref{dlhe}, lebo veľa zhrnutí dejov je dlhších ako 512 tokenov. Je vhodné vyskúšať viaceré metódy a zistiť, ktorá bude fungovať najlepšie. Takisto je potrebné rozdeliť dataset do 3 častí: train, test a valid. Každá z týchto 3 podmnožín je určitou percentuálnou časťou pôvodného datasetu a je nutné určiť aby toto rozdelenie bolo čo najlepšie. Ďalej, by mali všetky tieto podmnožiny mať zhruba rovnaké zastúpenie všetkých prípadov. V rámci tejto práce to znamená, aby čo možno všetky značky boli zastúpené v každej podmnožine, preto je vhodné aby dáta boli do týchto podmnožín náhodne rozdelené. Trénovacia sada býva zo všetkých najväčšia z týchto dát sa bude model učiť a snažiť sa nájsť správne nastavenia vnútorných stavov tak, aby sa čo najviac priblížil pôvodným výsledkom. Testovacia sada slúži na výpočet vyhodnocovacej metriky. Po každej fáze učenia, po určitom počte krokov, nasleduje fáza vyhodnotenia, teda kde model predpovedá ako by určil kľúčové dejové línie a porovnajú sa so skutočnými údajmi, spôsob porovnania závisí od vyhodnocovacích metrík \ref{metriky}, kde je vhodné vybrať správne tieto metriky, aby daná metrika nebola príliš prísna. Po tejto fáze model dostane spätnú väzbu a môže pokračovať v učení lepším spôsobom. Validačná sada slúži na to isté čo testovacia, akurát na to, že sa táto sada nepoužíva počas tréningu, ale až na finálnu validáciu modelu, a sú to teda dáta, ktoré model \uv{nikdy nevidel} a nie je žiadno ovplyvnená vyhodnocovacia metrika. 

Po tomto môže byť započatý proces učenia. Je zvykom nechať modelom prejsť trénovaciu sadu viac-krát, zvlášť keď je počet dát veľký. Jedno takéto \uv{prejdenie} sa nazýva epocha. IMDb dátová sada patrí medzi tie väčšie, preto bude nutné pustiť učenie na desiatky možno až stovky epoch, aby boli výsledky kvalitné. Treba podotknúť, že modely typu BERT sú pamäťovo veľmi náročné a spolu z veľkou dátovou sadou je výpočet veľmi náročný nie len na pamäť grafickej karty ale aj čo sa týka času. Preto je nutné trénovať takúto úlohu na výkonných grafických kartách, no napriek tomu môže výpočet trvať aj niekoľko dní. V praxi sa miesto klasických GPU používajú tzv. TPU\footnote{TPU -- tensor processing unit}, ktoré sú určené presne na trénovanie neurónových sietí a úlohy podobného typu. 

Pre naučenie klasifikátora odhadovať kľúčové dejové línie sa použije dátová sada z IMDb, kde vstupom budú zhrnutia dejov a výstupom budú pravdepodobnosti každej značky, ktoré budú znamenať na koľko si model myslí, že sa v zhrnutí nachádza daná kľúčová dejová línia. Zvolí sa prah, od ktorého sa budú kľúčové dejové línie klasifikovať na tie, ktoré sa v diele nachádzajú a na tie ktoré nie. Predpokladané výsledky sa porovnajú s reálnymi a BERT sa bude snažiť nachádzať súvislosti medzi kľúčovými dejovými líniami a slovami v zhrnutí. Nepredpokladá sa, že výsledky vyhodnocovacích metrík budú vysoké, lebo všeobecne viac-značková klasifikácia z veľa značkami nemá vynikajúce výsledky, takisto nemusia byť dáta dobre označkované a rovnako aj skracovanie textov bude znižovať hodnoty metrík. Je ale dôležitejšie ako bude model fungovať nad dátami, ktoré nie sú označkované a či dokáže aj v takých dátach nájsť kľúčové dejové línie a ako budú odrážať skutočnosť. Pre toto je vhodné vybrať si knihy (zhrnutia), ktoré poznáme, alebo sú nám známe a nechať model nech nad nimi predpovedá kľúčové dejové línie a výsledky ohodnotiť podľa vlastných predpokladov a očakávaní. Toto je vlastne cieľom tejto práce, či dokáže klasifikátor odhadnúť aké deje sa v príbehu nachádzajú a na koľko sú relevantné. Na toto budú využité zvyšné dátové sady.

Takýto klasifikátor možno takisto použiť na porovnávanie dvoch dejov a pomocou metrík podobnosti \ref{podobnost} sa porovnajú získané predpovede dvoch dejov a na základe tohoto porovnania sa zistí, či dané pravdepodobnostné vektory sú si podobné a teda či sú podobné aj deje. Úspešnosť a presnosť tohoto porovnania však do veľkej miery závisí od toho ako dobre sa budú predpovedať kľúčové dejové línie.

\section{Schéma systému}

Na obrázku \ref{schema} je zobrazené navrhovaná schéma výsledného systému. Šípky v tomto diagrame reprezentujú tok dát a obdĺžniky predstavujú konkrétne moduly.

Z webu je potrebné stiahnuť potrebné dátové sady, či už pomocou web scrapingu, alebo už priamo pripravené sady. Tieto dáta treba spracovať (HTML parsing) a odfiltrovať a vytvoriť z nich dátové sady, ktoré môžu byť použité na trénovanie neurónovej siete. Z internetu bude prevzatý aj pretrénovaný model BERT, ktorý sa doladí z vytvorených dátových sád. Výsledkom bude funkčný klasifikátor dejových línií. Bude však mať svoje chyby a proces trénovania sa bude opakovať viac-krát, s tým že sa budú upravovať dátové sady a parametre učenia, aby sa docielilo čo najlepších výsledkov. Z klasifikátora bude vychádzať aj porovnávač dejových línií.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.8\textwidth]{obrazky-figures/diagram.png}
	\caption{Navrhovaná schéma výsledného systému.}
	\label{schema}
\end{figure}

\section{Zhrnutie návrhu}

Hlavným cieľom práce je vytvoriť systém schopný zo zhrnutí dejov určiť o aké kľúčové deje \ref{kdl} sa v ňom jedná. Bude sa jednať o viac-značkovú klasifikáciu \ref{klasifikacia}, teda viac ako jeden dej sa môže vyskytnúť v jednom zhrnutí. Klasifikátorom kľúčových dejových línií bude pred-trénovaný model typu BERT \ref{bert}, ktorý bude adaptovaný na túto úlohu. Kvalitu modelu budú určovať metriky vyhodnotenia \ref{metriky}, no takisto vlastný názor.

Jedným z vedľajších cieľov je vytvoriť porovnávač dvoch dejových línií, ktorý bude z klasifikátora vychádzať. Tento porovnávač najskôr zistí pravdepodobnosti každej z kľúčových dejových línií v zhrnutí  v obidvoch dielach a potom tieto vektory porovná pomocou podobnostných metrík \ref{podobnost} a určí podobnosť týchto diel.

V neposlednom rade je cieľom zozbierať viacero zdrojov knižných dát a vytvoriť systém schopný extrahovať informácie o knihách a užívateľských recenzií z obľúbenej sociálnej siete zameranej na knihy -- Goodreads.

\chapter{Implementácia systému}
\label{implementacia}
V tejto kapitole bude priblížená implementácia systému popísaného v kapitole \ref{navrh} založená na dátach z kapitoly \ref{data}. Najskôr bude popísané z akých modulov sa riešenie skladá a z akých knižníc je riešenie vytvorené. Následne sú popísané jednotlivé moduly projektu. Je v nich objasnené čo všetko muselo byť naprogramované, konkrétne využité parametre a metriky vybrané po viacerých experimentoch. Možné námety na vylepšenia sú popísané v záverečnej podkapitole. V tejto kapitole je len popísané, ako systém funguje a ako bol implementovaný, no konkrétne príklady a experimenty budú popísané v nasledujúcej kapitole \ref{experimenty}.

\section{Architektúra projektu}

Implementačná fáza projektu pozostáva z 3 častí: 
\begin{itemize}
    \item Sťahovanie a spracovanie dát
    \item Trénovanie a adaptácia BERTa
    \item Načítanie BERTa pre vyhodnotenie
\end{itemize} 

Systém je implementovaný v jazyku \textit{Python 3}, ktorý je veľmi obľúbený a často používaný v úlohách týkajúcich sa analýzy dát a aplikáciach strojového učenia. 

Pre sťahovanie dát bola využitá knižnica \textit{Selenium}\footnote{https://www.selenium.dev/}, pre následné spracovanie stiahnutých súborov v HTML bola použitá knižnica  \textit{BeautifulSoup4}\footnote{https://beautiful-soup-4.readthedocs.io/}. Pre vytvorenie dátových sád sa používali \textit{Pandas}\footnote{https://pandas.pydata.org/}, \textit{Numpy}\footnote{https://numpy.org/} a knižnica \textit{Datasets}\footnote{https://huggingface.co/docs/datasets}, vytvorená priamo spoločnosťou HuggingFace\footnote{https://huggingface.co/} na vytváranie datasetov pre pred-trénované modely. Skripty na trénovanie neurónovej siete boli takisto používajú knižnicu od HuggingFace -- \textit{Transformers}\footnote{https://huggingface.co/docs/transformers}, ktorá ponúka jednoduché API pre jednoduché sťahovanie a trénovanie najmodernejších pred-trénovaných modelov pre viaceré frameworky určené pre strojové učenie. V tejto práci bol \textit{Transformers} použitý spolu s \textit{PyTorch}\footnote{https://pytorch.org/}. Už viac-krát spomenutý HuggingFace je web, poskytujú veľké množstvo voľne dostupných pred-trénovaných modelov pre rôzne typy úloh, z ktorého bol prevzatý aj model BERT pre účely tejto práce. Pre vyhodnocovanie úspešnosti klasifikácie a pre vyhodnocovanie podobnosti boli použité knižnice \textit{Sklearn}\footnote{https://scikit-learn.org/} a \textit{Scipy}\footnote{https://scipy.org/}.
 
\section{Dáta}

Ako bolo spomenuté v kapitole \ref{data}, v práci sa pracuje s troma dátovými sadami, ale iba dátové sady z Goodreads je nutné sťahovať, a spolu s dátovou sadou z IMDb aj určitým spôsobom spracovať. V tejto podkapitole je bližšie popísané ako sa dáta sťahovali a spracovávali.

\subsection*{Sťahovanie}

Sťahovaná bola iba dátová sada z Goodreads, lebo dátová sada z IMDb sa už nachádzala na serveroch KNOT, preto nebolo nutné tieto dáta znova sťahovať. Pre sťahovanie dát z Goodreads bolo nutné pripraviť zoznam URL, ktoré je treba stiahnuť. Tento zoznam následne sťahoval modul {\tt download}. Jedná sa o skript sťahujúci údaje z internetu a je v ňom využitá knižnica \textit{Selenium}, ktorá simuluje webový prehliadač, pomocou tzv. \textit{Chromedriver}. Proces sťahovania bol paralelizovaný medzi všetkých 77 serverov skupiny KNOT pre urýchlenie procesu sťahovania, no aj tak tento proces trval viac ako mesiac. Výstupom boli súbory typu HTML všetkých knižných stránok, ktoré je treba ďalej spracovať. Z neznámych dôvodov však servery Goodreads vracali dva druhy stránok typu HTML.

\subsection*{Spracovanie súborov typu HTML}

Takto stiahnuté dáta treba spracovať do formy, z ktorou sa ľahko manipuluje, preto všetky dátové sady sú súbory typu TSV\footnote{TSV -- Tab-separated values (hodnoty oddelené tabulátorom)}.

Keďže dáta z Goodreads sú dvojakého druhu, boli vytvorené aj dva skripty pre ich spracovanie. Jedná sa o moduly {\tt extract\_book\_info} a {\tt extract\_fuzzy\_book\_info}, ktoré pomocou \textit{BeautifulSoup4} extrahujú najdôležitejšie informácie najskôr o knihe samotnej a potom aj o všetkých recenziách danej knihy. Výstupom sú potom dva súbory typu TSV, jeden o informáciach o knihe, druhý obsahujúci užívateľské recenzie. V tabuľkách \ref{bookinfo} a \ref{reviewinfo} je popísané ako vyzerá konkrétny príklad jedného riadku oboch takto zostrojených dátových sád. 

Čo sa týka spracovania súborov typu HTML z IMDb, bol použitý rovnaký mechanizmus ako pri Goodreads dátach, pričom {\tt extract\_keywords\_imdb} je modulom, ktorý sa o to stará. Ako je možné si všimnúť v tabuľke \ref{imdb}, ktorá opäť ukazuje názornú ukážku z vytvorenej dátovej sady, nachádza sa tu len málo položiek dát. Je to kvôli tomu, že táto dátová sada slúži len na trénovanie a netreba k nej dodatočné informácie. Tieto dáta bolo nutné ešte odfiltrovať, pretože najskôr bol takto spracovaný dataset so všetkými kľúčovými slovami a so všetkými filmami/seriálmi. Filtrácia spočívala v tom, že najskôr boli vybraté kľúčové dejové línie (viď. príloha \ref{priloha-kdl}) a pokiaľ sa medzi kľúčovými slovami nachádzala aspoň jedna kľúčová dejová línia, tak bol záznam ponechaný a všetky kľúčové slová, mimo kľúčových dejových línií boli vymazané, inak bol vymazaný celý záznam.   

\subsection*{Spracovanie dátovej sady}

Predtým ako sú dáta predstavené neurónovej sieti je nutné ich pripraviť na formát, ktorým sa dokáže sieť učiť. Takisto je to aj v tomto prípade. Keďže je využitá knižnica \textit{Transformers}, tak bola využitá aj knižnica \textit{Datasets}, ktoré spolu dobre komunikujú, keďže sú vytvorené jednou spoločnosťou. Modul zabezpečujúci túto prípravu je {\tt prepare\_imdb\_data}. 

Jedná sa hlavne o prípravu kľúčových dejových línií do správneho formátu. Keďže neurónová sieť sa na díva ako na čísla, treba ich takto aj reprezentovať. Pre viac-značkovú klasifikáciu v tejto práci to znamená, že namiesto položky kľúčové dejové línie, ktorá obsahuje slovný zoznam kľúčových dejových línií platných pre dané zhrnutie, budú všetky kľúčové dejové línie (nie len tie, ktoré sú platné pre dané zhrnutie) mať vlastný záznam obsahujúci informáciu o tom, či je v danom zhrnutí platná (0,1). 

Okrem tohoto je upravené aj zhrnutie. Existujú totiž siete, ktoré rozlišujú malé a veľké písmena a tie ktoré nie. Pri zhrnutí deja nehrá veľkú úlohu veľkosť počiatočných písmen, preto bol použitý model, ktorý nerozlišuje veľké a malé písmená, preto boli všetky zhrnutia prevedené do malých písmen. Okrem toho, je nutné vyriešiť problém toho, že väčšina zhrnutí je dlhších ako 512 tokenov, teda je nutné nejako skrátiť toto zhrnutie. Najskôr bolo použité odstránenie tzv. \textit{stopwords}, ktoré reprezentujú slova, ktoré nemajú emocionálny význam a  nemajú teda čo dočinenia s dejom a sú viac-menej zbytočné, jedná sa o slová ako napr. \textit{of}, \textit{it}, \textit{the}, \textit{a}. Nemusí to byť najlepšou voľbou, ale aj takéto nepatrné zmeny môžu pomôcť skrátiť zhrnutie. Nepomôže to však všetkým zhrnutiam, preto je nutné ešte nejako skrátiť tieto zhrnutia. Boli vyskúšané viaceré metódy, no najlepšou a zároveň jednou z jednoduchších sa javí odseknutie iba posledných 510 tokenov \ref{dlhe}. Je to kvôli tomu, že rozuzlenie zápletky a teda určenie typu deja sa deje na konci zhrnutia. Rovnako sú odstránené interpunkcie. Tieto zhrnutia sú neskôr takisto prevedené na čísla, na identifikátory tokenov, pomocou tzv.\textit{tokenizer}. Ako spomenuté aj v návrhu, je nutné túto dátovú sadu rozdeliť na train, test a valid. Konkrétne sa použilo rozloženie 80:10:10, ktoré je často používané vo viacerých úlohách strojového učenia.

Výsledné dáta ktorými je model \uv{kŕmený} možno vidieť v tabuľke \ref{spracovane}.

\begin{table}[hbt]
\centering
\caption{Vzorka dát z IMDb dátovej sady spracovaná na trénovanie.}
\label{spracovane}
\begin{tabular}{|c|c|c|c|c|
>{\centering\arraybackslash}m{7em}|}
\hline
Movie/Series title & loss of father & moral dilemma & ... & death  & Plot summary \\
\hline
Saving Mr. Banks & 1 & 0  & ... & 1 &  doting father walter elias disney tom hanks...\\ 
\hline

\end{tabular}
\end{table}


\section{Klasifikácia}

V tejto podkapitole je popísaný konkrétny pred-trénovaný model použitý na trénovanie, ako prebiehal proces tréningu, parametre tréningu, konkrétne použité metriky a ako sa pracovalo s výsledným modelom. 

\subsection*{Stiahnutý model}

Z webu HuggingFace je možné si vybrať z veľkého množstva voľne dostupných pred-trénovaných modelov využiteľných na rôzne úlohy. Pre jednoduchosť bol zvolený {\tt roberta-base}. Jedná sa o menší model založený na princípoch BERT, ako z názvu vyplýva -- RoBERTa \cite{Liu:2019}, značí \textit{A Robustly Optimized BERT Pretraining Approach}, teda robustne optimalizovaný prístup pred-trénovania BERT. Dosahuje takisto trochu lepšie výsledky ako klasický BERT. Bola použitá \uv{menšia} varianta, lebo už aj táto varianta je dostatočne pamäťovo náročná a prínos väčšieho modelu nie je markantný.

\subsection*{Trénovanie/adaptácia}

Na trénovanie slúži modul {\tt trainer\_imdb}, ktorý používa \textit{Trainer API} z knižnice \textit{Transformers}. Pre proces trénovania je nutné nastaviť parametre trénovania: spôsob ako sa trénovanie bude vyhodnocovať a dátové sady na tréning a priebežne vyhodnocovanie. Toto všetko je v \textit{Trainer API} zabezpečené veľmi priamočiaro, aj vďaka spolupráci s \textit{Datasets}. Všetky parametre tréningu je možné si pozrieť v \todo{kóde}, no z tých dôležitejších treba uviezť aspoň následovné. Po 2000 krokoch vždy nasleduje vyhodnocovanie, miera učenia (angl. learning rate) bola po viacerých experimentoch zvolená na 3e-5, veľkosť dávok (batch size) bola 4, aj preto ,že väčšia už nemohla byť kvôli pamäti na grafickej karte. Táto nízka veľkosť dávky bola ale vyvážená gradientovými akumulačnými krokmi (angl. gradient accumulation steps). Počet epoch vo finálnej verzií je 30, čo aj tak trvalo niekoľko dní na natrénovanie. Vyhodnocovacie metrikou, ktoré určovali úspešnosť modelu boli viaceré. Konkrétne klasické f1 skóre, jeho makro a mikro varianta, presnosť (Accuracy) a varianty priemernej presnosti. Hlavnou, ktorá určovala zlepšenie bolo klasické f1 skóre. Dátovou sadou pre trénovanie je spomínaná dátová sada train a pre priebežne vyhodnotenie to je dátová sada test. Dátová sada valid je použitá po tréningu na celkový výpočet úspešnosti. 

Trénovanie bežalo na grafickej karte NVidia RTX3090 TURBO na jednom zo strojoch skupiny KNOT. Karta má 24 GB veľkosť operačnej pamäte, no aj tak to v niektorých prípadoch experimentov bolo málo. 

Počas tréningu sa modely priebežne ukladajú, aby mohli byť ľahko načítané a použité.

\subsection*{Načítanie modelu}

Najlepší model je načítaný z pamäte a s ním sú potom vykonávané experimenty a vyhodnotenia. Model sa načítava pre jednu z troch vecí: výpočet vyhodnocovacích metrík, určenie kľúčových dejových línií, porovnanie dvoch dejov. Modul {\tt load\_model\_imdb} je zodpovedný za výpočet vyhodnocovacích metrík. Modelom sa nechá prejsť dátová sada valid a všetky predpovede modelu sa ukladajú a nakoniec sa porovnajú s očakávanými výsledkami, vypočítajú sa a vypíšu sa výsledky. Metriky, ktoré sa používajú sú: f1-skóre, mikro f1-skóre, makro f1-skóre, presnosť (Accuracy), priemerná presnosť (Average precision), mikro priemerná presnosť a makro priemerná presnosť. Iné metriky sú dosť prísne, preto boli použité práve tieto. Výsledky modelu sa dajú priebežne získavať počas trénovania, teda určitá predstava o výsledkoch je už počas adaptácie. Avšak prácou s dátami, ktoré model nikdy nevidel je získané objektívnejšie zhodnotenie modelu. Toto načítanie trvá aj niekoľko minú, keďže model musí všetky položky z valid dátovej sady vyhodnotiť, to zaberá najviac času, potom už výpočet metrík je časovo nenáročný. 

Ďalej sa model načítava pre určenie kľúčových dejových línií ľubovoľného zhrnutia. Vstupom je ľubovoľné zhrnutie, ktoré je opäť pomocou \textit{tokenizer} prevedené do jazyka, ktorému model rozumie a rovnako musí byť zhrnutie upravené a skrátené tak ako pri spracovaní dátovej sady. Výstupom nie je nič iné ako predpovedané kľúčové dejové línie. Takisto sú k výstupom vypísané jednotlivé pravdepodobnosti kľúčových dejových línií, teda na koľko si bol model istý, že sa jedná o danú kľúčovú dejovú líniu. Toto zabezpečuje modul {\tt predict\_plot}.

Pre porovnanie dvoch dejov slúži modul {\tt compare\_plots}, ktorý robí to isté ako modul popísaný v predošlom odstavci, akurát to robí pre dve zhrnutia. Vypočítané pravdepodobností oboch zhrnutí pre všetky kľúčové dejové línie sú porovnané pomocou metrík podobnosti \ref{podobnost}. Všetky tri metriky, teda Spearmanov korelačný koeficient, Pearsonov korelačný koeficient a Kosínusová podobnosť sú spolu spriemerované a výsledok určuje percento podobnosti týchto dvoch dejov.


\chapter{Experimentálne vyhodnotenie a diskusia}
\label{experimenty}


\section{Dataset}
kriticke zhoodnotenie ci je prinosom a je vyuzitelna

\section{Maximálna presnosť}

\begin{table}[hbt]
\centering
\caption{Výsledná úspešnosť klasifikátora určujúci kľúčové dejové línie.}
\label{vysledky}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\(Acc.\) & \(F1\) & \(F1_{Micro}\) & \(F1_{Macro}\) & \(Avg. Pre.\) & \(Avg. Pre._{Micro}\) &  \(Avg. Pre._{Macro}\) \\
\hline
23.3 & 30.7 & 36.9 & 27.1 & 45.4 & 33.8 & 24.5 \\ 
\hline

\end{tabular}
\end{table}

\section{Využitie}
zvasty


\section{Príklady}
imdb podareny 96h/a time to kill nepodareny, porovnanie podarene/nepodarene (s nemom, cindirela, dve rozdielne uplne)
booksumaries podarene, nepodarene, porovnanie podarene/nepodarene (nieco co poznas zhruba)
goodreads zhrnutie podarene, nepodarene
goodreads recenzia podarene, nepodarene? (kde je nejaky dej aspon)
= 12 ?? neni to moc, ak iba strucny popis tak nie
screenshoty ? tabulky ? 


\section{Možné vylepšenia}
+ gui, porovnavanie zo vsetkymi datami
viac kdl, lepsich....
lepsie data -hlavne, doraz, zalezi na zhrnuti, aj oznackovani, aj o infomacii v zhrnuti, tazko
dlhsi trening
lepsie hyperpara


\chapter{Záver}
\label{zaver}


%===============================================================================